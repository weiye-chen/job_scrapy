import time
import random
from DrissionPage import ChromiumPage
import db_handler as db
import json
import os
from itertools import product

def fetch_jd_content(page, job_id, security_id, lid):
    """
    è¿›å…¥èŒä½è¯¦æƒ…é¡µæŠ“å– JD å…¨æ–‡
    """
    # æ„é€ è¯¦æƒ…é¡µ URL (Bossç›´è˜çš„æ ‡å‡†æ ¼å¼)
    detail_url = f'https://www.zhipin.com/job_detail/{job_id}.html?securityId={security_id}&lid={lid}'

    # å»ºè®®åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€ï¼Œæˆ–è€…ç›´æ¥è·³è½¬
    page.get(detail_url)

    # ç­‰å¾… JD æ–‡æœ¬å®¹å™¨åŠ è½½
    # Boss çš„ JD é€šå¸¸åœ¨ class ä¸º job-sec-text çš„ div ä¸­
    try:
        jd_ele = page.wait.ele_displayed('.job-sec-text', timeout=5)
        if jd_ele:
            return jd_ele.text
        return ""
    except:
        print(f"âš ï¸ èŒä½ {job_id} JD æŠ“å–è¶…æ—¶ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨éªŒè¯")
        return ""


def process_list_and_jds(json_data, page):
    """
    å¤„ç†åˆ—è¡¨æ•°æ®ï¼Œå¹¶å¾ªç¯æŠ“å–æ¯ä¸€ä¸ªèŒä½çš„ JD
    """
    job_list = json_data.get('zpData', {}).get('jobList', [])

    for item in job_list:
        job_id = item.get('encryptJobId')
        security_id = item.get('securityId')
        lid = item.get('lid')
        job_name = item.get('jobName')

        print(f"ğŸ” æ­£åœ¨æ·±åº¦æŠ“å–: {job_name}...")

        # --- æ ¸å¿ƒé¿å‘é€»è¾‘ï¼šä¸è¦æŠ“å¤ªå¿« ---
        time.sleep(random.uniform(5, 10))

        jd_text = fetch_jd_content(page, job_id, security_id, lid)

        if jd_text:
            # å°†åŒ…å« JD çš„å®Œæ•´æ•°æ®å­˜å…¥æ•°æ®åº“
            db.save_job_with_jd(item, jd_text)
            print(f"âœ… å·²æˆåŠŸå­˜å…¥ JD (é•¿åº¦: {len(jd_text)})")

        # æŠ“å®Œä¸€ä¸ªå›åˆ°åˆ—è¡¨é¡µï¼Œæˆ–è€…ä¿æŒåœ¨è¯¦æƒ…é¡µç»§ç»­ä¸‹ä¸€ä¸ªè·³è½¬
        # å»ºè®®ç›´æ¥ page.get è®¿é—®ä¸‹ä¸€ä¸ªè¯¦æƒ…é¡µ


if __name__ == '__main__':
    db.init_db()
    # 1. è¯»å–é…ç½®æ–‡ä»¶
    config_path = 'config.json'
    if not os.path.exists(config_path):
        print(f"âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {config_path}")
        exit()

    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)

    # è·å–ä¸¤ä¸ªç‹¬ç«‹çš„åˆ—è¡¨
    queries = config.get('queries', [])
    cities = config.get('cities', [])
    interval = config.get('delay_between_tasks', 10)

    # 2. å¯åŠ¨æµè§ˆå™¨
    boss_page = ChromiumPage()

    # 3. ä½¿ç”¨ product è¿›è¡Œç»„åˆéå† (Query x City)
    # product(['A', 'B'], [1, 2]) -> (A, 1), (A, 2), (B, 1), (B, 2)
    task_combinations = list(product(queries, cities))
    total_tasks = len(task_combinations)

    print(f"ğŸ“Š å·²ç”Ÿæˆç»„åˆä»»åŠ¡ï¼Œå…±è®¡ {total_tasks} ç»„ã€‚")

    for index, (query, city) in enumerate(task_combinations, 1):
        print(f"\nğŸš€ ä»»åŠ¡è¿›åº¦ [{index}/{total_tasks}]: {query} @ åŸå¸‚ä»£ç :{city}")

        # å¼€å¯ç›‘å¬
        boss_page.listen.start('joblist.json')

        # æ„é€  URL
        target_url = f'https://www.zhipin.com/web/geek/job?query={query}&city={city}'
        boss_page.get(target_url)

        # ç­‰å¾…æ•°æ®åŒ…
        res = boss_page.listen.wait(timeout=10)

        if res:
            data = res.response.body
            # å¤„ç†æ•°æ®å’ŒæŠ“å– JD
            process_list_and_jds(data, boss_page)
            print(f"âœ… å®ŒæˆæŠ“å–")
        else:
            print(f"âš ï¸ å“åº”è¶…æ—¶ï¼Œå¯èƒ½æ˜¯å› ä¸º IP é™åˆ¶æˆ–éªŒè¯ç ã€‚")
            # å»ºè®®ï¼šå¦‚æœè¶…æ—¶ï¼Œå¯ä»¥åœ¨è¿™é‡ŒåŠ ä¸€ä¸ª input("è¯·å¤„ç†éªŒè¯ç åæŒ‰å›è½¦...")
            # è¿™æ ·å¯ä»¥åœ¨ä¸ä¸­æ–­ç¨‹åºçš„æƒ…å†µä¸‹äººå·¥æ¥å…¥ã€‚

        # ä»»åŠ¡é—´çš„ä¼‘æ¯
        if index < total_tasks:  # æœ€åä¸€ä¸ªä»»åŠ¡å®Œåä¸éœ€è¦ä¼‘æ¯
            print(f"â˜• ä¼‘æ¯ {interval} ç§’ååˆ‡æ¢ç»„åˆ...")
            time.sleep(interval)

    print("\nğŸ‰ å…¨é‡ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼æ•°æ®åº“å·²æ›´æ–°ã€‚")